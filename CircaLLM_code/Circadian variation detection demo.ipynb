{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input File Requirements \n",
    "\n",
    "Input file should be an Excel. The table consists of three parts: Symbol column, data columns, and label column.\n",
    "\n",
    "## 1. Column Structure\n",
    " \n",
    "### **Symbol Column**\n",
    "- **Column Name**: `Symbol`  \n",
    "- **Content**: Gene identifiers.  \n",
    "- **Position**: First column.  \n",
    " \n",
    "### **Data Columns (Dual Time Series)**\n",
    "- **Column Naming Rule**: `{time}_{dup}_{series}`  \n",
    "  - `time`: Time point (e.g., 0, 4, 8).  \n",
    "  - `dup`: Replication number (e.g., 0, 1, 2).  \n",
    "  - `series`: Time series identifier (0 or 1).  \n",
    "- **Sorting Rules**:  \n",
    "  1. **Group by `dup`**: Columns with the same `dup` are grouped together.  \n",
    "  2. **Sort by `time` within groups**: Within each `dup` group, columns are sorted by `time` in ascending order.  \n",
    "  3. **Sort groups by `dup`**: Groups are ordered by `dup` (e.g., `dup=0` first, then `dup=1`).  \n",
    "  4. **All `series=0` columns first, then `series=1` columns**:  \n",
    "     - First, list **all `series=0` columns** (ordered by `dup` and `time`).  \n",
    "     - Then, list **all `series=1` columns** (ordered by `dup` and `time`).  \n",
    "- **Example Column Names**:  \n",
    "  - Series 1: `0_0_0`, `4_0_0`, `8_0_0`, `0_1_0`, `4_1_0`, `8_1_0`  \n",
    "  - Series 2: `0_0_1`, `4_0_1`, `8_0_1`, `0_1_1`, `4_1_1`, `8_1_1`  \n",
    " \n",
    "### **Label Columns (4 columns)**\n",
    "- **Column Names**:  \n",
    "  - `period_diff`: Indicates **significant difference in period** (1 = significant, 0 = not significant).  \n",
    "  - `amp_diff`: Indicates **significant difference in amplitude** (1 = significant, 0 = not significant).  \n",
    "  - `phase_diff`: Indicates **significant difference in phase** (1 = significant, 0 = not significant).  \n",
    "  - `baseline_diff`: Indicates **significant difference in baseline** (1 = significant, 0 = not significant).  \n",
    "- **Content**: Binary labels (0 or 1).  \n",
    "- **Position**: Last four columns.  \n",
    "- **Note**: If uncertain, set all labels to 1.  \n",
    " \n",
    "---\n",
    " \n",
    "## 2. Example Table Structure\n",
    "| Symbol | 0_0_0 | 4_0_0 | 8_0_0 | 0_1_0 | 4_1_0 | 8_1_0 | 0_0_1 | 4_0_1 | 8_0_1 | 0_1_1 | 4_1_1 | 8_1_1 | period_diff | amp_diff | phase_diff | baseline_diff |\n",
    "|--------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------------|----------|------------|---------------|\n",
    "| GENE1  | 7.342 | 4.928 | 3.213 | 8.029 | 5.750 | 4.837 | 7.401 | 4.950 | 3.250 | 8.102 | 5.780 | 4.850 | 1           | 0        | 1          | 0             |\n",
    "| GENE2  | 8.029 | 5.750 | 3.421 | 8.258 | 5.849 | 3.729 | 8.102 | 5.780 | 3.450 | 8.301 | 5.880 | 3.750 | 0           | 1        | 0          | 1             |\n",
    " \n",
    "---\n",
    " \n",
    "## 3. Data Filling Instructions\n",
    "1. **Symbol Column**: Fill in unique gene identifiers.  \n",
    "2. **Data Columns**:  \n",
    "   - Populate all `{time}_{dup}_{series}` columns in the correct order.  \n",
    "3. **Label Columns**:  \n",
    "   - For each gene, assign 0 or 1 for each difference category.  \n",
    "   - If uncertain, set all labels to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ts import multi_convert_to_ts\n",
    "\n",
    "# 使用示例 ---------------------------------------------------\n",
    "# 假设输入文件格式：\n",
    "# Symbol,0_1,0_2,0_3,3_1,3_2,3_3,...,21_3,label\n",
    "# gene1,26.39,23.50,22.03,28.25,19.15,22.67,...,23.29,1\n",
    "# gene2,66.86,63.80,53.70,60.53,60.44,50.98,...,66.91,0\n",
    "\n",
    "multi_convert_to_ts(\n",
    "    input_csv='../example_data/example_data_t2.csv',\n",
    "    output_ts='../example_data/t2/test.ts',\n",
    "    problem_name='example',\n",
    "    label_cols=['amp', 'phase', 'baseline', 'period']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读入T5-small进circallm，然后以后用这个circallm进行预训练\n",
    "from argparse import Namespace\n",
    "from models.circaLLM import CIRCALLM\n",
    "config_dict = {\n",
    "    \"task_name\": \"diffrhythm\", \n",
    "    \"model_name\": \"CIRCALLM\", \n",
    "    \"transformer_type\": \"encoder_only\", \n",
    "    \"freeze_embedder\":False,\n",
    "    \"freeze_encoder\":False,\n",
    "    \"freeze_head\":False,\n",
    "    \"learning_rate\":1e-6,\n",
    "    \"num_epochs\":30,\n",
    "    \"n_channels\": 2,\n",
    "    \"num_class\": 4,\n",
    "    'reduction': 'mean',\n",
    "    \"type\":'real',\n",
    "    \"d_model\": None, \n",
    "    \"seq_len\": 72,\n",
    "    'enable_gradient_checkpointing': False,\n",
    "    \"enable_FAN\":True,\n",
    "    \"enable_FAN_gate\":True,\n",
    "    \"patch_len\": 6, \n",
    "    \"patch_stride_len\": 6, \n",
    "    \"device\": \"cpu\", \n",
    "    \"transformer_backbone\": \"google/flan-t5-small\", \n",
    "    \"model_kwargs\": {},\n",
    "    \"t5_config\": {\n",
    "        \"architectures\": [\"T5ForConditionalGeneration\"],\n",
    "        \"d_ff\": 1024,\n",
    "        \"d_kv\": 64,\n",
    "        \"d_model\": 512,\n",
    "        \"decoder_start_token_id\": 0,\n",
    "        \"dropout_rate\": 0.1,\n",
    "        \"eos_token_id\": 1,\n",
    "        \"feed_forward_proj\": \"gelu\",\n",
    "        \"initializer_factor\": 1.0,\n",
    "        \"is_encoder_decoder\": True,\n",
    "        \"layer_norm_epsilon\": 1e-06,\n",
    "        \"model_type\": \"t5\",\n",
    "        \"n_positions\": 72,\n",
    "        \"num_decoder_layers\": 6,\n",
    "        \"num_heads\": 8,\n",
    "        \"num_layers\": 6,\n",
    "        \"output_past\": True,\n",
    "        \"pad_token_id\": 0,\n",
    "        \"relative_attention_max_distance\": 128,\n",
    "        \"relative_attention_num_buckets\": 32,\n",
    "        \"tie_word_embeddings\": False,\n",
    "        \"use_cache\": True,\n",
    "        \"vocab_size\": 32128\n",
    "    }\n",
    "}\n",
    "\n",
    "# 将字典转换为 Namespace 对象\n",
    "config = Namespace(**config_dict)\n",
    "\n",
    "model =CIRCALLM(config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "def train_epoch(model,device,train_dataloader,optimizer,criterion,scheduler):\n",
    "    '''\n",
    "    Train encoder and classification head (with accelerate enabled)\n",
    "    '''\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    all_targets,all_preds,all_scores = [],[],[]\n",
    "    running_loss, t_running_loss, amp_running_loss, phase_running_loss, mesor_running_loss=0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    correct, correct_T, correct_Amp, correct_Phase, correct_Mesor = 0,0,0,0,0\n",
    "    all_sample,t_sample,amp_sample,phase_sample,mesor_sample=0,0,0,0,0\n",
    "    # i=0\n",
    "    for batch_data_1, input_mask_1, x_marks_1, batch_data_2, input_mask_2, x_marks_2, targets in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "        # if i==2:\n",
    "        #     break\n",
    "        # i=i+1\n",
    "        optimizer.zero_grad()\n",
    "        batch_data_1, batch_data_2 = batch_data_1.to(device).float(), batch_data_2.to(device).float()\n",
    "        input_mask_1, input_mask_2 = input_mask_1.long().to(device), input_mask_2.long().to(device)\n",
    "        x_marks_1, x_marks_2 = x_marks_1.to(device), x_marks_2.to(device)\n",
    "\n",
    "        mask = (targets != -1).to(device)\n",
    "        all_sample += mask.sum().item()\n",
    "        t_sample += mask[:,0].sum().item()\n",
    "        amp_sample += mask[:,1].sum().item()\n",
    "        phase_sample += mask[:,2].sum().item()\n",
    "        mesor_sample += mask[:,3].sum().item()\n",
    "\n",
    "        labels_clean = torch.where(mask.detach().cpu(), targets, torch.zeros_like(targets))\n",
    "        target=labels_clean.float().to(device)\n",
    "\n",
    "        all_targets.extend(targets.detach().int().cpu().numpy())\n",
    "\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else torch.float32):\n",
    "            output = model(x_enc=batch_data_1, input_mask=input_mask_1, x_mark=x_marks_1, \n",
    "                           x_enc2=batch_data_2, input_mask2=input_mask_2, x_mark2=x_marks_2, reduction=config.reduction)\n",
    "            logits=output.logits\n",
    "            raw_loss = criterion(logits, target) * mask.float()\n",
    "            loss=raw_loss.sum() / mask.sum().item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        #loss计算\n",
    "        running_loss += loss.item()\n",
    "        t_running_loss += raw_loss.sum(axis=0)[0].item() / (mask.sum(axis=0)[0].item() + 1e-6)\n",
    "        amp_running_loss += raw_loss.sum(axis=0)[1].item() / (mask.sum(axis=0)[1].item() + 1e-6)\n",
    "        phase_running_loss += raw_loss.sum(axis=0)[2].item() / (mask.sum(axis=0)[2].item() + 1e-6)\n",
    "        mesor_running_loss += raw_loss.sum(axis=0)[3].item() / (mask.sum(axis=0)[3].item() + 1e-6)\n",
    "        #预测标签获取\n",
    "        scores=torch.sigmoid(logits)\n",
    "        predicted = (scores > 0.5).int()\n",
    "        predicted = torch.where(mask, predicted, torch.tensor(-1))\n",
    "        all_preds.extend(predicted.detach().cpu().numpy())\n",
    "\n",
    "        correct += ((predicted==target.int())*mask).sum().item()\n",
    "        correct_T += ((predicted[:,0]==target[:,0].int())*mask[:,0]).sum().item()\n",
    "        correct_Amp += ((predicted[:,1]==target[:,1].int())*mask[:,1]).sum().item()\n",
    "        correct_Phase += ((predicted[:,2]==target[:,2].int())*mask[:,2]).sum().item()\n",
    "        correct_Mesor += ((predicted[:,3]==target[:,3].int())*mask[:,3]).sum().item()\n",
    "\n",
    "        #计算预测为正类的概率\n",
    "        all_scores.extend(torch.where(mask, scores, torch.tensor(-1)).detach().to(torch.float).cpu().numpy())\n",
    "\n",
    "    all_targets = np.array(all_targets)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_scores = np.array(all_scores)\n",
    "    \n",
    "    avg_loss = running_loss / len(train_dataloader)\n",
    "    avg_t_loss, avg_amp_loss = t_running_loss / len(train_dataloader), amp_running_loss / len(train_dataloader)\n",
    "    avg_phase_loss, avg_mesor_loss = phase_running_loss / len(train_dataloader), mesor_running_loss / len(train_dataloader)\n",
    "\n",
    "\n",
    "    avg_accuracy = correct / all_sample\n",
    "\n",
    "    t_accuracy, amp_accuracy = correct_T / t_sample, correct_Amp / amp_sample\n",
    "    phase_accuracy, mesor_accuracy = correct_Phase / phase_sample, correct_Mesor / mesor_sample \n",
    "\n",
    "    loss={\"avg_loss\":avg_loss,\n",
    "        \"avg_t_loss\":avg_t_loss,\n",
    "        \"avg_amp_loss\":avg_amp_loss,\n",
    "        \"avg_phase_loss\":avg_phase_loss,\n",
    "        \"avg_mesor_loss\":avg_mesor_loss}\n",
    "    \n",
    "    accuracy={\"avg_accuracy\":avg_accuracy,\n",
    "              \"t_accuracy\":t_accuracy,\n",
    "              \"amp_accuracy\":amp_accuracy,\n",
    "              \"phase_accuracy\":phase_accuracy,\n",
    "              \"mesor_accuracy\":mesor_accuracy}\n",
    "\n",
    "    result={\n",
    "        \"loss\":loss,\n",
    "        \"accuracy\":accuracy,\n",
    "        \"targets\":all_targets.tolist(),\n",
    "        \"preds\":all_preds.tolist(),\n",
    "        \"scores\":all_scores.tolist(),\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def test_epoch(model,dataloader,device,criterion):\n",
    "    return evaluate_epoch(model,dataloader,device,criterion)\n",
    "    \n",
    "def evaluate_epoch(model,dataloader,device,criterion):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    all_targets, all_preds, all_scores = [],[],[]\n",
    "    running_loss, t_running_loss, amp_running_loss, phase_running_loss, mesor_running_loss=0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    correct, correct_T, correct_Amp, correct_Phase, correct_Mesor = 0,0,0,0,0\n",
    "    all_sample,t_sample,amp_sample,phase_sample,mesor_sample=0,0,0,0,0\n",
    "    # i=0\n",
    "    with torch.no_grad():\n",
    "        for batch_data_1, input_mask_1, x_marks_1, batch_data_2, input_mask_2, x_marks_2, targets in tqdm(dataloader, total=len(dataloader)):\n",
    "            # if i==2:\n",
    "            #     break\n",
    "            # i=i+1\n",
    "            batch_data_1, batch_data_2 = batch_data_1.to(device).float(), batch_data_2.to(device).float()\n",
    "            input_mask_1, input_mask_2 = input_mask_1.long().to(device), input_mask_2.long().to(device)\n",
    "            x_marks_1, x_marks_2 = x_marks_1.to(device), x_marks_2.to(device)\n",
    "            \n",
    "            mask = (targets != -1).to(device)\n",
    "            all_sample += mask.sum().item()\n",
    "            t_sample += mask[:,0].sum().item()\n",
    "            amp_sample += mask[:,1].sum().item()\n",
    "            phase_sample += mask[:,2].sum().item()\n",
    "            mesor_sample += mask[:,3].sum().item()\n",
    "            labels_clean = torch.where(mask.detach().cpu(), targets, torch.zeros_like(targets))\n",
    "            target=labels_clean.float().to(device)\n",
    "            \n",
    "            all_targets.extend(targets.detach().int().cpu().numpy())\n",
    "            \n",
    "            with torch.autocast(device_type='cuda', dtype=torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else torch.float32):\n",
    "                output = model(x_enc=batch_data_1, input_mask=input_mask_1, x_mark=x_marks_1,\n",
    "                               x_enc2=batch_data_2, input_mask2=input_mask_2, x_mark2=x_marks_2, reduction=config.reduction)\n",
    "                logits=output.logits\n",
    "                raw_loss = criterion(logits, target) * mask.float()\n",
    "                loss=raw_loss.sum() / mask.sum().item()\n",
    "\n",
    "            #loss计算\n",
    "            running_loss += loss.item()\n",
    "            t_running_loss += raw_loss.sum(axis=0)[0].item() / (mask.sum(axis=0)[0].item() + 1e-6)\n",
    "            amp_running_loss += raw_loss.sum(axis=0)[1].item() / (mask.sum(axis=0)[1].item() + 1e-6)\n",
    "            phase_running_loss += raw_loss.sum(axis=0)[2].item() / (mask.sum(axis=0)[2].item() + 1e-6)\n",
    "            mesor_running_loss += raw_loss.sum(axis=0)[3].item() / (mask.sum(axis=0)[3].item() + 1e-6)\n",
    "\n",
    "            #获取预测标签\n",
    "            scores=torch.sigmoid(logits)*mask\n",
    "            predicted = (scores > 0.5).int()\n",
    "\n",
    "            predicted = torch.where(mask, predicted, torch.tensor(-1))\n",
    "            all_preds.extend(predicted.detach().cpu().numpy())\n",
    "\n",
    "            #统计预测正确的标签的个数\n",
    "            correct += ((predicted==target.int())*mask).sum().item()\n",
    "            correct_T += ((predicted[:,0]==target[:,0].int())*mask[:,0]).sum().item()\n",
    "            correct_Amp += ((predicted[:,1]==target[:,1].int())*mask[:,1]).sum().item()\n",
    "            correct_Phase += ((predicted[:,2]==target[:,2].int())*mask[:,2]).sum().item()\n",
    "            correct_Mesor += ((predicted[:,3]==target[:,3].int())*mask[:,3]).sum().item()\n",
    "\n",
    "            #计算预测为正类的概率\n",
    "            all_scores.extend(torch.where(mask, scores, torch.tensor(-1)).detach().to(torch.float).cpu().numpy())\n",
    "    \n",
    "    #计算关键指标precision,recall,F1-score,auc,AP,mAP\n",
    "    all_targets = np.array(all_targets)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_scores = np.array(all_scores)\n",
    "\n",
    "    #计算每个epoch平均loss和accuracy\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    avg_t_loss, avg_amp_loss = t_running_loss / len(dataloader), amp_running_loss / len(dataloader)\n",
    "    avg_phase_loss, avg_mesor_loss = phase_running_loss / len(dataloader), mesor_running_loss / len(dataloader)\n",
    "\n",
    "    avg_accuracy = correct / all_sample\n",
    "\n",
    "    t_accuracy, amp_accuracy = correct_T / t_sample, correct_Amp / amp_sample\n",
    "    phase_accuracy, mesor_accuracy = correct_Phase / phase_sample, correct_Mesor / mesor_sample \n",
    "\n",
    "    loss={\"avg_loss\":avg_loss,\n",
    "        \"avg_t_loss\":avg_t_loss,\n",
    "        \"avg_amp_loss\":avg_amp_loss,\n",
    "        \"avg_phase_loss\":avg_phase_loss,\n",
    "        \"avg_mesor_loss\":avg_mesor_loss}\n",
    "    \n",
    "    accuracy={\"avg_accuracy\":avg_accuracy,\n",
    "              \"t_accuracy\":t_accuracy,\n",
    "              \"amp_accuracy\":amp_accuracy,\n",
    "              \"phase_accuracy\":phase_accuracy,\n",
    "              \"mesor_accuracy\":mesor_accuracy}\n",
    "    \n",
    "    result={\n",
    "        \"loss\":loss,\n",
    "        \"accuracy\":accuracy,\n",
    "        \"targets\":all_targets.tolist(),\n",
    "        \"preds\":all_preds.tolist(),\n",
    "        \"scores\":all_scores.tolist(),\n",
    "    }\n",
    "    return result\n",
    "import os\n",
    "def save_checkpoint(model,savePath=\"best_model.pth\"):#\"best_valModel.pth\",\"current_model.pth\"\n",
    "    path = os.path.join(\"saved_nnets/RealDST-T1\")\n",
    "    #mkdir if not exist\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(path, savePath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "state_dict=torch.load(\"pretrained/Task2/best_model.pth\")\n",
    "model.load_state_dict(state_dict)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "file_paths=\"../example_data/t2/\"\n",
    "result_fold = '../example_data/t2/result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import TRUE\n",
    "from data_provider.classfication_datasets import MulGroup_MultipleDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.logging import CustomLogger\n",
    "from utils.metrics import Metric\n",
    "from datetime import datetime\n",
    "import torch\n",
    "current_time = datetime.now()\n",
    "c_time = current_time.strftime(\"%y_%m_%d_%H_%M\")\n",
    "\n",
    "seed=77\n",
    "for filepath in file_paths:\n",
    "    # 创建 MultipleDataset 实例并加载数据\n",
    "    test_dataset = MulGroup_MultipleDataset(data_split=\"test\", file_paths=[file_paths],seq_len=72,seed=seed)\n",
    "    torch.manual_seed(seed)\n",
    "    id=test_dataset.labels[:,0]\n",
    "    test_dataset.labels=test_dataset.labels[:,1:5].astype(int)\n",
    "    train_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    # test_result=train_epoch(model,device,train_dataloader,optimizer,criterion,scheduler)\n",
    "    test_result=test_epoch(model, train_dataloader, device, criterion)\n",
    "    # print(f\"{currentFile}: Test Accuracy: {test_result['accuracy'][0]:.4f}\")\n",
    "\n",
    "    labels=np.array(test_result['targets'])\n",
    "    predict=np.array(test_result['preds'])\n",
    "    target1,target2,target3,target4=labels[:,0],labels[:,1],labels[:,2],labels[:,3]\n",
    "    predict1,predict2,predict3,predict4=predict[:,0],predict[:,1],predict[:,2],predict[:,3]\n",
    "    target1,target2,target3,target4=target1[target1 !=-1],target2[target2 !=-1],target3[target3 !=-1],target4[target4 !=-1]\n",
    "    predict1,predict2,predict3,predict4=predict1[predict1 !=-1],predict2[predict2 !=-1],predict3[predict3 !=-1],predict4[predict4 !=-1]\n",
    "    \n",
    "    # scores=test_result['scores']\n",
    "    report1=Metric.get_classification_report(target1,predict1)\n",
    "    print(\"Period\"+report1)\n",
    "    report2=Metric.get_classification_report(target2,predict2)\n",
    "    print(\"Amplitude\"+report2)\n",
    "    report3=Metric.get_classification_report(target3,predict3)\n",
    "    print(\"Phase\"+report3)\n",
    "    report4=Metric.get_classification_report(target4,predict4)\n",
    "    print(\"Mesor\"+report4)\n",
    "\n",
    "    sss=np.array(test_result['scores'])\n",
    "    score1,score2,score3,score4=sss[:,0],sss[:,1],sss[:,2],sss[:,3]\n",
    "    score1,score2,score3,score4=score1[score1 !=-1],score2[score2 !=-1],score3[score3 !=-1],score4[score4 !=-1]\n",
    "\n",
    "    resSave={\n",
    "    'accuracy':test_result['accuracy'],\n",
    "    'target':{'period':target1.tolist(),'amp':target2.tolist(),'phase':target3.tolist(),'mesor':target4.tolist()},\n",
    "    'preds':{'period':predict1.tolist(),'amp':predict2.tolist(),'phase':predict3.tolist(),'mesor':predict4.tolist()},\n",
    "    'scores':{'period':score1.tolist(),'amp':score2.tolist(),'phase':score3.tolist(),'mesor':score4.tolist()}}\n",
    "    resSave['ID']=id.tolist()\n",
    "\n",
    "    Metric.save_metrics(resSave, result_fold, \"current_res.json\", 0, \"example\", mode='w')\n",
    "\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.pro_json as pro_json\n",
    "\n",
    "metrics_result = pro_json.calculate_multiclass_metrics(json_path='../example_data/t2/result/example/current_res.json')\n",
    "\n",
    "pro_json.process_multiclass_json_to_csv(\n",
    "    json_path=\"../example_data/t2/result/example/current_res.json\", \n",
    "    output_fold=\"../example_data/t2/result/example/\"  \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circallm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
