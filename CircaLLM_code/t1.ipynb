{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input File Requirements\n",
    "\n",
    "Input file should be an Excel. The table consists of three parts: Symbol column, data columns, and label column.\n",
    "\n",
    "## 1. Column Structure\n",
    "\n",
    "###  **Symbol Column**\n",
    "- **Column Name**: `Symbol`\n",
    "- **Content**: Gene identifiers.\n",
    "- **Position**: First column.\n",
    "\n",
    "###  **Data Columns**\n",
    "- **Column Naming Rule**: `time_dup`\n",
    "  - `time`: The time point of the sample.\n",
    "  - `dup`: The replication number of the sample.\n",
    "- **Sorting Rules**:\n",
    "  - Columns with the same `dup` value are grouped together.\n",
    "  - Within each group, columns are sorted by `time` in ascending order.\n",
    "  - Groups are sorted by `dup` in ascending order.\n",
    "- **Example Column Names**: `0_0`, `4_0`, `8_0`, `0_1`, `4_1`, `8_1`, etc.\n",
    "- **Content**: Expression values of the corresponding gene at specific times and replications.\n",
    "\n",
    "###  **Label Column**\n",
    "- **Column Name**: `label`\n",
    "- **Content**: A label indicating whether the gene oscillates, with values `0` or `1`.\n",
    "  - `0`: The gene does not oscillate.\n",
    "  - `1`: The gene oscillates.\n",
    "- **Position**: Last column.\n",
    "- **Note**: If the `label` is uncertain, it can be set to `1` for all entries.\n",
    "\n",
    "## 2. Example Table Structure\n",
    "\n",
    "| Symbol | 0_0  | 4_0  | 8_0  | ... | label |\n",
    "|--------|------|------|------|-----|-------|\n",
    "| GENE1  | 0.36314 | 0.838363 | 0.850397 | ... | 0     |\n",
    "| GENE2  | 3.49872 | 3.780274 | 3.770533 | ... | 0     |\n",
    "| ...    | ...  | ...  | ...  | ... | ...   |\n",
    "\n",
    "## 3. Data Filling Instructions\n",
    "- **Symbol Column**: Fill in the unique identifiers for the genes.\n",
    "- **Data Columns**: Fill in the expression values of the corresponding gene at specific times and replications.\n",
    "- **Label Column**: Fill in `0` or `1` based on whether the gene oscillates. If uncertain, fill in `1` for all entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ts import singal_convert_to_ts\n",
    "\n",
    "singal_convert_to_ts(\n",
    "    input_csv='../example_data/example_data_t1.csv',\n",
    "    output_ts='../example_data/t1/test.ts',\n",
    "    problem_name='example',\n",
    "    label_col='label'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from models.circaLLM import CIRCALLM\n",
    "config_dict = {\n",
    "    \"task_name\": \"classification\", \n",
    "    \"model_name\": \"CIRCALLM\", \n",
    "    \"transformer_type\": \"encoder_only\", \n",
    "    \"freeze_embedder\":False,\n",
    "    \"freeze_encoder\":False,\n",
    "    \"freeze_head\":False,\n",
    "    \"learning_rate\":1e-6,\n",
    "    \"num_epochs\":20,\n",
    "    \"n_channels\": 1,\n",
    "    \"num_class\": 2,\n",
    "    'reduction': 'mean',\n",
    "    \"d_model\": None, \n",
    "    \"seq_len\": 72,\n",
    "    'enable_gradient_checkpointing': False,\n",
    "    \"enable_FAN\":True,\n",
    "    \"enable_FAN_gate\":True,\n",
    "    \"patch_len\": 6, \n",
    "    \"patch_stride_len\": 6, \n",
    "    \"device\": \"cpu\", \n",
    "    \"transformer_backbone\": \"google/flan-t5-small\", \n",
    "    \"model_kwargs\": {},\n",
    "    \"t5_config\": {\n",
    "        \"architectures\": [\"T5ForConditionalGeneration\"],\n",
    "        \"d_ff\": 1024,\n",
    "        \"d_kv\": 64,\n",
    "        \"d_model\": 512,\n",
    "        \"decoder_start_token_id\": 0,\n",
    "        \"dropout_rate\": 0.1,\n",
    "        \"eos_token_id\": 1,\n",
    "        \"feed_forward_proj\": \"gated-gelu\",\n",
    "        \"initializer_factor\": 1.0,\n",
    "        \"is_encoder_decoder\": True,\n",
    "        \"layer_norm_epsilon\": 1e-06,\n",
    "        \"model_type\": \"t5\",\n",
    "        \"n_positions\": 72,\n",
    "        \"num_decoder_layers\": 6,\n",
    "        \"num_heads\": 8,\n",
    "        \"num_layers\": 6,\n",
    "        \"output_past\": True,\n",
    "        \"pad_token_id\": 0,\n",
    "        \"relative_attention_max_distance\": 128,\n",
    "        \"relative_attention_num_buckets\": 32,\n",
    "        \"tie_word_embeddings\": False,\n",
    "        \"use_cache\": True,\n",
    "        \"vocab_size\": 32128\n",
    "    }\n",
    "}\n",
    "\n",
    "config = Namespace(**config_dict)\n",
    "\n",
    "model =CIRCALLM(config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "state_dict=torch.load(\"pretrained/Task1/best_model.pth\")#best_model\n",
    "model.load_state_dict(state_dict[\"model_state_dict\"])#state_dict[\"model_state_dict\"]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "\n",
    "def test_epoch(model,dataloader,device,criterion):\n",
    "    return evaluate_epoch(model,dataloader,device,criterion)\n",
    "    \n",
    "def evaluate_epoch(model,dataloader,device,criterion):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    all_targets, all_preds, all_scores = [],[],[]\n",
    "    running_loss, correct, total = 0.0, 0,0\n",
    "    with torch.no_grad():\n",
    "        for batch_data, input_mask, x_marks, targets in tqdm(dataloader, total=len(dataloader)):\n",
    "\n",
    "            batch_data = batch_data.to(device).float()\n",
    "            input_mask, x_marks=input_mask.long().to(device), x_marks.to(device)\n",
    "            all_targets.extend(targets.detach().cpu().numpy())\n",
    "            targets=targets.unsqueeze(1).float().to(device)\n",
    "            total += targets.size(0)\n",
    "\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else torch.float32):\n",
    "                output = model(x_enc=batch_data,input_mask=input_mask,x_mark=x_marks,reduction=config.reduction)\n",
    "                logits=output.logits\n",
    "                loss = criterion(logits, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            scores=torch.sigmoid(logits)\n",
    "            predicted = (scores > 0.5).int()\n",
    "            all_preds.extend(predicted.detach().cpu().numpy())\n",
    "            correct += (predicted == targets.int()).sum().item()\n",
    "            all_scores.extend(scores.detach().to(torch.float).cpu().numpy())\n",
    "    \n",
    "    all_targets = np.array(all_targets)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_scores = np.array(all_scores)\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    result={\n",
    "        \"loss\":[avg_loss],\n",
    "        \"accuracy\":[accuracy],\n",
    "        \"targets\":all_targets.tolist(),\n",
    "        \"preds\":all_preds.tolist(),\n",
    "        \"scores\":all_scores.tolist(),\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from data_provider.classfication_datasets import MultipleDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.logging import CustomLogger\n",
    "from utils.metrics import Metric\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "seed = 77\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "test_file_fold = \"../example_data/t1/\"  \n",
    "assert os.path.exists(test_file_fold), f\"测试文件夹不存在: {test_file_fold}\"\n",
    "result_fold = '../example_data/t1/result/'\n",
    "\n",
    "test_dataset = MultipleDataset(\n",
    "    data_split=\"aper\",      \n",
    "    file_paths=[test_file_fold],\n",
    "    seq_len=72,\n",
    "    seed=seed,\n",
    "    Realcase=True\n",
    ")\n",
    "print(test_dataset.data.shape)\n",
    "torch.manual_seed(seed)\n",
    "id=test_dataset.labels[:,0]\n",
    "test_dataset.labels=test_dataset.labels[:,1].astype(int)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-4,total_steps=10*len(test_dataloader))\n",
    "trainSave={'loss':[],'accuracy':[],'targets':[],'preds':[],'scores':[]}\n",
    "label=test_dataset.labels\n",
    "pos_weights = torch.tensor([np.sum(label)/(len(label) - np.sum(label))],dtype=torch.float32)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weights.to(device))\n",
    "\n",
    "test_result=test_epoch(model, test_dataloader, device, criterion)\n",
    "print(f\"Test Accuracy: {test_result['accuracy'][0]:.4f}\")\n",
    "for kk in trainSave:\n",
    "    trainSave[kk].extend(test_result[kk])\n",
    "trainSave['ID']=id.tolist()\n",
    "\n",
    "Metric.save_metrics(trainSave, result_fold, \"current_res.json\", 0, \"example\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.pro_json as pro_json\n",
    "\n",
    "acc, pre, rec, f1, auroc, aupr = pro_json.calculate_binary_metrics(json_path='../example_data/t1/result/example/current_res.json')\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {pre:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"AUROC: {auroc:.4f}\")\n",
    "print(f\"AUPR: {aupr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.pro_json as pro_json\n",
    "\n",
    "pro_json.process_json_to_csv(\n",
    "    json_path=\"../example_data/t1/result/example/current_res.json\", \n",
    "    output_csv=\"../example_data/t1/result/example/example_circallm.csv\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(),\"/mnt/disk/zxc/TimeSeriesLLM/circaLLM/pretrained/RealDST_T1/Geod_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circallm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
